{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "709fc424-02af-466b-a728-0dd4067dfbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from rouge_score import rouge_scorer\n",
    "import evaluate\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7e1dc64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>transcription</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A 23-year-old white female presents with comp...</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "      <td>Allergic Rhinitis</td>\n",
       "      <td>SUBJECTIVE:,  This 23-year-old white female pr...</td>\n",
       "      <td>allergy / immunology, allergic rhinitis, aller...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Consult for laparoscopic gastric bypass.</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Laparoscopic Gastric Bypass Consult - 2</td>\n",
       "      <td>PAST MEDICAL HISTORY:, He has difficulty climb...</td>\n",
       "      <td>bariatrics, laparoscopic gastric bypass, weigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Consult for laparoscopic gastric bypass.</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Laparoscopic Gastric Bypass Consult - 1</td>\n",
       "      <td>HISTORY OF PRESENT ILLNESS: , I have seen ABC ...</td>\n",
       "      <td>bariatrics, laparoscopic gastric bypass, heart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2-D M-Mode. Doppler.</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 1</td>\n",
       "      <td>2-D M-MODE: , ,1.  Left atrial enlargement wit...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d m-mode, dopple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2-D Echocardiogram</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 2</td>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d, doppler, echo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>4994</td>\n",
       "      <td>Patient having severe sinusitis about two to ...</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "      <td>Chronic Sinusitis</td>\n",
       "      <td>HISTORY:,  I had the pleasure of meeting and e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4995</td>\n",
       "      <td>This is a 14-month-old baby boy Caucasian who...</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "      <td>Kawasaki Disease - Discharge Summary</td>\n",
       "      <td>ADMITTING DIAGNOSIS: , Kawasaki disease.,DISCH...</td>\n",
       "      <td>allergy / immunology, mucous membranes, conjun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4996</td>\n",
       "      <td>A female for a complete physical and follow u...</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "      <td>Followup on Asthma</td>\n",
       "      <td>SUBJECTIVE: , This is a 42-year-old white fema...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4997</td>\n",
       "      <td>Mother states he has been wheezing and coughing.</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "      <td>Asthma in a 5-year-old</td>\n",
       "      <td>CHIEF COMPLAINT: , This 5-year-old male presen...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4998</td>\n",
       "      <td>Acute allergic reaction, etiology uncertain, ...</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "      <td>Allergy Evaluation Consult</td>\n",
       "      <td>HISTORY: , A 34-year-old male presents today s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4999 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                        description  \\\n",
       "0              0   A 23-year-old white female presents with comp...   \n",
       "1              1           Consult for laparoscopic gastric bypass.   \n",
       "2              2           Consult for laparoscopic gastric bypass.   \n",
       "3              3                             2-D M-Mode. Doppler.     \n",
       "4              4                                 2-D Echocardiogram   \n",
       "...          ...                                                ...   \n",
       "4994        4994   Patient having severe sinusitis about two to ...   \n",
       "4995        4995   This is a 14-month-old baby boy Caucasian who...   \n",
       "4996        4996   A female for a complete physical and follow u...   \n",
       "4997        4997   Mother states he has been wheezing and coughing.   \n",
       "4998        4998   Acute allergic reaction, etiology uncertain, ...   \n",
       "\n",
       "                medical_specialty                                sample_name  \\\n",
       "0            Allergy / Immunology                         Allergic Rhinitis    \n",
       "1                      Bariatrics   Laparoscopic Gastric Bypass Consult - 2    \n",
       "2                      Bariatrics   Laparoscopic Gastric Bypass Consult - 1    \n",
       "3      Cardiovascular / Pulmonary                    2-D Echocardiogram - 1    \n",
       "4      Cardiovascular / Pulmonary                    2-D Echocardiogram - 2    \n",
       "...                           ...                                        ...   \n",
       "4994         Allergy / Immunology                         Chronic Sinusitis    \n",
       "4995         Allergy / Immunology      Kawasaki Disease - Discharge Summary    \n",
       "4996         Allergy / Immunology                        Followup on Asthma    \n",
       "4997         Allergy / Immunology                    Asthma in a 5-year-old    \n",
       "4998         Allergy / Immunology                Allergy Evaluation Consult    \n",
       "\n",
       "                                          transcription  \\\n",
       "0     SUBJECTIVE:,  This 23-year-old white female pr...   \n",
       "1     PAST MEDICAL HISTORY:, He has difficulty climb...   \n",
       "2     HISTORY OF PRESENT ILLNESS: , I have seen ABC ...   \n",
       "3     2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
       "4     1.  The left ventricular cavity size and wall ...   \n",
       "...                                                 ...   \n",
       "4994  HISTORY:,  I had the pleasure of meeting and e...   \n",
       "4995  ADMITTING DIAGNOSIS: , Kawasaki disease.,DISCH...   \n",
       "4996  SUBJECTIVE: , This is a 42-year-old white fema...   \n",
       "4997  CHIEF COMPLAINT: , This 5-year-old male presen...   \n",
       "4998  HISTORY: , A 34-year-old male presents today s...   \n",
       "\n",
       "                                               keywords  \n",
       "0     allergy / immunology, allergic rhinitis, aller...  \n",
       "1     bariatrics, laparoscopic gastric bypass, weigh...  \n",
       "2     bariatrics, laparoscopic gastric bypass, heart...  \n",
       "3     cardiovascular / pulmonary, 2-d m-mode, dopple...  \n",
       "4     cardiovascular / pulmonary, 2-d, doppler, echo...  \n",
       "...                                                 ...  \n",
       "4994                                                NaN  \n",
       "4995  allergy / immunology, mucous membranes, conjun...  \n",
       "4996                                                NaN  \n",
       "4997                                                NaN  \n",
       "4998                                                NaN  \n",
       "\n",
       "[4999 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./mtsamples.csv')\n",
    "df['transcription'] = df.transcription.astype(str)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b23adc",
   "metadata": {},
   "source": [
    "# ROUGE F1 Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81f840d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_calcer = rouge_scorer.RougeScorer([\n",
    "    'rouge1', \n",
    "    'rouge2', \n",
    "    'rouge3',\n",
    "    'rouge4',\n",
    "    'rougeL',\n",
    "    'rougeLsum'\n",
    "], use_stemmer = True)\n",
    "\n",
    "def calc_rouge(row):\n",
    "    short_text, full_text = row['description'], row['transcription']        \n",
    "\n",
    "    try:\n",
    "        rouges = rouge_calcer.score(short_text, full_text)\n",
    "        return rouges['rouge1'][2], rouges['rouge2'][2], rouges['rouge3'][2], rouges['rouge4'][2], rouges['rougeL'][2], rouges['rougeLsum'][2]\n",
    "    except Exception as e:\n",
    "        return 0.0, 0.0, 0.0, 0.0, 0.0, 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "050cd334",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['rouge1_f1', 'rouge2_f1', 'rouge3_f1', 'rouge4_f1', 'rougeL_f1', 'rougeLsum_f1']] = df.apply(calc_rouge, axis = 1, result_type = 'expand')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f1139a",
   "metadata": {},
   "source": [
    "# BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6182766",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "def calc_bertscore(row):\n",
    "    short_text, full_text = row['description'], row['transcription'] \n",
    "\n",
    "    try:\n",
    "        result = bertscore.compute(\n",
    "                predictions = [short_text],\n",
    "                references = [full_text],\n",
    "                model_type = \"microsoft/deberta-large-mnli\",\n",
    "                lang = \"en\")\n",
    "\n",
    "        return result[\"f1\"][0]\n",
    "    except:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a550384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    }
   ],
   "source": [
    "df['bertscore_f1'] = df.apply(calc_bertscore, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8b2599",
   "metadata": {},
   "source": [
    "# BLEURT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a72664ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint /mnt/data/hf/metrics/bleurt/bleurt-tiny-128/downloads/extracted/599cd3ff6a3bbad54e145d867ccea405bb98c2b832fb29b50fb02089a1026530/bleurt-tiny-128.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint /mnt/data/hf/metrics/bleurt/bleurt-tiny-128/downloads/extracted/599cd3ff6a3bbad54e145d867ccea405bb98c2b832fb29b50fb02089a1026530/bleurt-tiny-128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Config file found, reading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Config file found, reading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Will load checkpoint bert_custom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Will load checkpoint bert_custom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loads full paths and checks that files exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loads full paths and checks that files exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... name:bert_custom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... name:bert_custom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... vocab_file:vocab.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... vocab_file:vocab.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... bert_config_file:bert_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... bert_config_file:bert_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... do_lower_case:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... do_lower_case:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... max_seq_length:128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... max_seq_length:128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating BLEURT scorer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating BLEURT scorer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating WordPiece tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating WordPiece tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating Eager Mode predictor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating Eager Mode predictor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model.\n",
      "I0000 00:00:1751856942.698179 2136909 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8279 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:02:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    }
   ],
   "source": [
    "bleurt = evaluate.load(\"bleurt\", config_name = \"bleurt-tiny-128\")\n",
    "\n",
    "def calc_bleu(row):\n",
    "    short_text, full_text = row['description'], row['transcription']\n",
    "\n",
    "    with tf.device(\"/CPU:0\"):\n",
    "        try:\n",
    "            result = bleurt.compute(\n",
    "                    predictions = [short_text],\n",
    "                    references = [full_text],\n",
    "                    )\n",
    "            return result[\"scores\"][0]\n",
    "        except:\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd078da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bleurt'] = df.apply(calc_bleu, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0931479a",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1de9fc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('mtsamples_with_metrics.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc12339-0ead-4d4d-b529-bf074b6ca203",
   "metadata": {},
   "source": [
    "#  HHEM 2.1 model from Vectara (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d6eb47e-1abb-406c-92b6-35c6d62bbbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kilnaar/anaconda3/envs/ai574-pocs/lib/python3.11/site-packages/weave/scorers/scorer_types.py:107: UserWarning: You have a GPU available, you can pass `device='cuda'` to the scorer init, this will speed up model loading and inference\n",
      "  check_cuda(self.device)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact hallucination_hhem_scorer:v0, 421.31MB. 8 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   8 of 8 files downloaded.  \n",
      "Done. 0:0:1.0 (436.1MB/s)\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"WANDB_BASE_URL\"] = \"https://api.wandb.ai\"\n",
    "from weave.scorers import WeaveHallucinationScorerV1\n",
    "\n",
    "hallucination_scorer = WeaveHallucinationScorerV1()\n",
    "\n",
    "def hallucination_score(query, context, output):\n",
    "    try:\n",
    "        result = hallucination_scorer.score(\n",
    "            query = query,\n",
    "            context = context,\n",
    "            output = output\n",
    "        )\n",
    "    \n",
    "        return result.metadata['score']\n",
    "    except:\n",
    "        return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f772311-ea63-4971-b475-f4cdbf95c0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_llama = pd.read_csv('mtsamples_with_llama.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c673ab5-7334-4a8f-bed4-7f410cfc987c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (711 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "df_llama['med-llama-summary-hallucination-score'] = df_llama.apply(lambda x: hallucination_score(x.transcription, x.description, x['med-llama-summary']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7051c8c2-d18a-45c5-90bb-60e452d45eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_llama.to_csv('mtsamples_with_llama_hhem_score.csv', index = False, quoting = csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1af8b7-cdaa-4a3b-8c70-6ab42707a9f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
