{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dcd4bcf-556c-4619-a124-1b30508525f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, textwrap\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57dc2f5c-4498-421c-a8f8-2d7bd268121d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OptimizedModule(\n",
       "  (_orig_mod): Gemma3ForConditionalGeneration(\n",
       "    (model): Gemma3Model(\n",
       "      (vision_tower): SiglipVisionModel(\n",
       "        (vision_model): SiglipVisionTransformer(\n",
       "          (embeddings): SiglipVisionEmbeddings(\n",
       "            (patch_embedding): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14), padding=valid)\n",
       "            (position_embedding): Embedding(4096, 1152)\n",
       "          )\n",
       "          (encoder): SiglipEncoder(\n",
       "            (layers): ModuleList(\n",
       "              (0-26): 27 x SiglipEncoderLayer(\n",
       "                (layer_norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "                (self_attn): SiglipAttention(\n",
       "                  (k_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                  (v_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                  (q_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                  (out_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                )\n",
       "                (layer_norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "                (mlp): SiglipMLP(\n",
       "                  (activation_fn): PytorchGELUTanh()\n",
       "                  (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "                  (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (post_layernorm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (multi_modal_projector): Gemma3MultiModalProjector(\n",
       "        (mm_soft_emb_norm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
       "        (avg_pool): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
       "      )\n",
       "      (language_model): Gemma3TextModel(\n",
       "        (embed_tokens): Gemma3TextScaledWordEmbedding(262208, 2560, padding_idx=0)\n",
       "        (layers): ModuleList(\n",
       "          (0-33): 34 x Gemma3DecoderLayer(\n",
       "            (self_attn): Gemma3Attention(\n",
       "              (q_proj): Linear(in_features=2560, out_features=2048, bias=False)\n",
       "              (k_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "              (v_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "              (o_proj): Linear(in_features=2048, out_features=2560, bias=False)\n",
       "              (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "              (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "            )\n",
       "            (mlp): Gemma3MLP(\n",
       "              (gate_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "              (up_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "              (down_proj): Linear(in_features=10240, out_features=2560, bias=False)\n",
       "              (act_fn): PytorchGELUTanh()\n",
       "            )\n",
       "            (input_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "            (post_attention_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "            (pre_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "            (post_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "        (rotary_emb): Gemma3RotaryEmbedding()\n",
       "        (rotary_emb_local): Gemma3RotaryEmbedding()\n",
       "      )\n",
       "    )\n",
       "    (lm_head): Linear(in_features=2560, out_features=262208, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "MODEL_ID = \"google/medgemma-4b-it\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    return_tensors = \"pt\",\n",
    "    padding = True,\n",
    "    truncation = True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map = {\"\": 1},\n",
    "    torch_dtype = \"auto\",\n",
    "    trust_remote_code = True\n",
    ")\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model = torch.compile(model, mode = \"reduce-overhead\",\n",
    "                      fullgraph = False,\n",
    "                      dynamic = True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6072732b-64fa-4900-ae89-1642bb76a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_text = \"\"\"\n",
    "Non-steroidal anti-inflammatory drugs are not only potent analgesics and antipyretics but also nephrotoxins, and may cause \n",
    "electrolyte disarray. In addition to the commonly expected effects, including hyperkalemia, hyponatremia, acute renal injury, \n",
    "renal cortical necrosis, and volume retention, glomerular disease with or without nephrotic syndrome or nephritis can occur as \n",
    "well including after years of seemingly safe administration. Minimal change disease, secondary membranous glomerulonephritis, \n",
    "and acute interstitial nephritis are all reported glomerular lesions seen with non-steroidal anti-inflammatory use. We report a \n",
    "patient who used non-steroidal anti-inflammatory drugs for years without diabetes, chronic kidney disease, or proteinuria; he \n",
    "then developed severe nephrotic range proteinuria with 7 g of daily urinary protein excretion. Renal biopsy showed minimal \n",
    "change nephropathy, a likely secondary membranous glomerulonephritis, and acute interstitial nephritis present simultaneously\n",
    "in one biopsy. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd440072-008a-4317-b8f4-9930fc1ecce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_cfg = GenerationConfig(\n",
    "    max_new_tokens = 128,\n",
    "    temperature = 0.1,\n",
    "    top_p = 0.9,\n",
    "    repetition_penalty = 1.1,\n",
    "    do_sample = True,\n",
    "    no_repeat_ngram_size = 6,\n",
    ")    \n",
    "\n",
    "def summarize(medical_text):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": textwrap.dedent(f\"\"\"\n",
    "                Below is an abstract from a medical paper.\n",
    "    \n",
    "                ```text\n",
    "                {medical_text.strip()}\n",
    "                ```\n",
    "    \n",
    "                **Task:** Produce a 20-word summary **and end with a full stop (.) when you are done.**\n",
    "                Use clear, professional medical language.\n",
    "                Don't include a greeting or introduction.\n",
    "            \"\"\"),\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    encoded = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt = True,\n",
    "        tokenize = True,\n",
    "        padding = True,\n",
    "        max_length = 1024,\n",
    "        truncation = True,\n",
    "        return_tensors = \"pt\",\n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated = model.generate(\n",
    "            encoded,  \n",
    "            generation_config = gen_cfg, \n",
    "            return_dict_in_generate = False,\n",
    "        )\n",
    "    \n",
    "    summary = tokenizer.decode(generated[0], skip_special_tokens = True)\n",
    "    summary = summary.split('\\nmodel\\n')[-1]\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd8225f3-c343-4f75-b47b-a2508e522fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "V0713 22:59:38.620000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/4] [__recompiles] Recompiling function forward in /home/kilnaar/anaconda3/envs/ai574-pocs/lib/python3.11/site-packages/transformers/models/gemma3/modeling_gemma3.py:1275\n",
      "V0713 22:59:38.620000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/4] [__recompiles]     triggered by the following guard failure(s):\n",
      "V0713 22:59:38.620000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/4] [__recompiles]     - 0/3: ___check_obj_id(past_key_values.key_cache[0], 127542436505520)\n",
      "V0713 22:59:38.620000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/4] [__recompiles]     - 0/2: ___check_obj_id(past_key_values.key_cache[0], 127542692976240)\n",
      "V0713 22:59:38.620000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/4] [__recompiles]     - 0/1: ___check_obj_id(past_key_values.key_cache[0], 127542692984976)\n",
      "V0713 22:59:38.620000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/4] [__recompiles]     - 0/0: ___check_obj_id(past_key_values.key_cache[0], 127543084877296)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NSAID use can induce glomerular diseases like minimal change disease and membranous glomerulonephritis in patients without pre-existing conditions.\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(medical_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cdd921c-f57e-433b-8b2a-fc066eb34b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "df = pd.read_csv('./data/mtsamples.csv')\n",
    "df['transcription'] = df.transcription.astype(str)\n",
    "df['description'] = df.description.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fa23b84-c6a3-4ba8-a654-7d061f834176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "V0713 22:59:47.728000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/5] [__recompiles] Recompiling function forward in /home/kilnaar/anaconda3/envs/ai574-pocs/lib/python3.11/site-packages/transformers/models/gemma3/modeling_gemma3.py:1275\n",
      "V0713 22:59:47.728000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/5] [__recompiles]     triggered by the following guard failure(s):\n",
      "V0713 22:59:47.728000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/5] [__recompiles]     - 0/4: ___check_obj_id(past_key_values.key_cache[0], 127542414562832)\n",
      "V0713 22:59:47.728000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/5] [__recompiles]     - 0/3: ___check_obj_id(past_key_values.key_cache[0], 127542436505520)\n",
      "V0713 22:59:47.728000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/5] [__recompiles]     - 0/2: ___check_obj_id(past_key_values.key_cache[0], 127542692976240)\n",
      "V0713 22:59:47.728000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/5] [__recompiles]     - 0/1: ___check_obj_id(past_key_values.key_cache[0], 127542692984976)\n",
      "V0713 22:59:47.728000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/5] [__recompiles]     - 0/0: tensor 'attention_mask' size mismatch at index 3. expected 402, actual 526\n",
      "V0713 22:59:56.370000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/6] [__recompiles] Recompiling function forward in /home/kilnaar/anaconda3/envs/ai574-pocs/lib/python3.11/site-packages/transformers/models/gemma3/modeling_gemma3.py:1275\n",
      "V0713 22:59:56.370000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/6] [__recompiles]     triggered by the following guard failure(s):\n",
      "V0713 22:59:56.370000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/6] [__recompiles]     - 0/5: ___check_obj_id(past_key_values.key_cache[0], 127542429208976)\n",
      "V0713 22:59:56.370000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/6] [__recompiles]     - 0/4: ___check_obj_id(past_key_values.key_cache[0], 127542414562832)\n",
      "V0713 22:59:56.370000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/6] [__recompiles]     - 0/3: ___check_obj_id(past_key_values.key_cache[0], 127542436505520)\n",
      "V0713 22:59:56.370000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/6] [__recompiles]     - 0/2: ___check_obj_id(past_key_values.key_cache[0], 127542692976240)\n",
      "V0713 22:59:56.370000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/6] [__recompiles]     - 0/1: ___check_obj_id(past_key_values.key_cache[0], 127542692984976)\n",
      "V0713 22:59:56.370000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/6] [__recompiles]     - 0/0: tensor 'attention_mask' size mismatch at index 3. expected 402, actual 738\n",
      "V0713 23:00:04.998000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/7] [__recompiles] Recompiling function forward in /home/kilnaar/anaconda3/envs/ai574-pocs/lib/python3.11/site-packages/transformers/models/gemma3/modeling_gemma3.py:1275\n",
      "V0713 23:00:04.998000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/7] [__recompiles]     triggered by the following guard failure(s):\n",
      "V0713 23:00:04.998000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/7] [__recompiles]     - 0/6: ___check_obj_id(past_key_values.key_cache[0], 127542303053808)\n",
      "V0713 23:00:04.998000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/7] [__recompiles]     - 0/5: ___check_obj_id(past_key_values.key_cache[0], 127542429208976)\n",
      "V0713 23:00:04.998000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/7] [__recompiles]     - 0/4: ___check_obj_id(past_key_values.key_cache[0], 127542414562832)\n",
      "V0713 23:00:04.998000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/7] [__recompiles]     - 0/3: ___check_obj_id(past_key_values.key_cache[0], 127542436505520)\n",
      "V0713 23:00:04.998000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/7] [__recompiles]     - 0/2: ___check_obj_id(past_key_values.key_cache[0], 127542692976240)\n",
      "V0713 23:00:04.998000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/7] [__recompiles]     - 0/1: ___check_obj_id(past_key_values.key_cache[0], 127542692984976)\n",
      "V0713 23:00:04.998000 2027762 site-packages/torch/_dynamo/guards.py:3006] [0/7] [__recompiles]     - 0/0: tensor 'attention_mask' size mismatch at index 3. expected 402, actual 1151\n"
     ]
    }
   ],
   "source": [
    "df['model-summary'] = df.transcription.apply(summarize)\n",
    "df['model-name'] = 'med-gemma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec3702cb-ea8e-460e-beae-7eb8cb3224f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/mtsamples_with_gemma.csv', index = False, quoting = csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f5e345-399e-46eb-90d1-158a17d1243b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
