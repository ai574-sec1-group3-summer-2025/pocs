{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Specialty Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Problem statement\n",
    "\n",
    "# Edit all the Mardown cells below with the appropriate information \n",
    "# Run all cells, containing your code \n",
    "# Save this Jupyter with the outputs of your executed cells\n",
    "#\n",
    "# PS: Save again the notebook with this outcome.\n",
    "# PSPS: Don't forget to include the dataset in your submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Team 3:**\n",
    "* Balachander Srinivasan\n",
    "* Christopher Umbel\n",
    "* Mahfuzur Rahman\n",
    "\n",
    "**Course:** AI 574 â€“ Natural Language Processing (Summer, 2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "* This project  .....\n",
    "    \n",
    "    \n",
    "    \n",
    "* **Keywords:** House price prediction, real estate ,..., \n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection\n",
    "* **Source(url):** https://www.kaggle.com/datasets/tboyle10/medicaltranscriptions/data\n",
    "* **Short Description:** The data set of anonymized medical transcription reports from Boyle (2018)\n",
    "\n",
    "* **Keywords:** description, medical_specialty, sample_name, transcription, and keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required packages\n",
    "\n",
    "Run the following command to install the required packages:\n",
    "```\n",
    "pip install -r ./requirements.txt\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding, EarlyStoppingCallback\n",
    "import torch\n",
    "\n",
    "from data_utils import DataUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 256\n",
    "BATCH_SIZE = 16\n",
    "DS_SPLIT = 0.2\n",
    "MIN_SPECIALITY_THRESHOLD = 100\n",
    "DATASET_PATH = 'data/mtsamples.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATASET_PATH, index_col=0)\n",
    "df.info()\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils = DataUtils()\n",
    "_ = utils.class_distribution(df.medical_specialty, 'Medical Specialty', show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['transcription'].fillna('')\n",
    "texts = texts.map(utils.clean_text)\n",
    "tok_freq = Counter(tok for row in texts for tok in row.split() if tok)\n",
    "\n",
    "print(\"\\nMost common tokens:\")\n",
    "for tok, freq in tok_freq.most_common (10):\n",
    "    print(f\"Token: '{tok}', Frequency: {freq}\")\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(texts))\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title(\"Word Cloud of Transcriptions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.DataFrame()\n",
    "stats['length'] = texts.apply(len)\n",
    "stats['word_cnt'] = texts.apply(lambda x: len(x.split()))\n",
    "print(f\"\\n{stats.describe()}\")\n",
    "stats.hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology\n",
    "\n",
    "1. Explan your Deep Learning process / methodology\n",
    "\n",
    "\n",
    "\n",
    "2. Introduce the Deep Neural Networks you used in your project\n",
    " * Model 1\n",
    "    * Description \n",
    " \n",
    " * Model 2\n",
    "    * Description\n",
    " \n",
    " * Ensemble method\n",
    "     * Description \n",
    " \n",
    " \n",
    "3. Add keywords  \n",
    "**Keywords:** natural language processing, sentiment analysis, clustering, binary classification, multi-label classification, prediction\n",
    "\t___\n",
    " **Example**\n",
    "* ConvNet\n",
    "    * A convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery(source Wikipedia). \n",
    " \n",
    "* **Keywords:** supervised learning, classification, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Distil-BioBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing\n",
    "\n",
    "* Enumerate and present the main steps you preformed in the data preprocessing\n",
    "* Add your code and interpret the outcome of main steps/functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'nlpie/distil-biobert'\n",
    "df = pd.read_csv(DATASET_PATH, usecols=['medical_specialty', 'transcription'])\n",
    "\n",
    "df = utils.handle_nulls(df)\n",
    "df = utils.handle_duplicates(df)\n",
    "\n",
    "df['text'] = df['transcription'].map(utils.clean_text)\n",
    "df['medical_specialty'] = df['medical_specialty'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_specialities = ['Surgery', 'Consult - History and Phy.',  'Radiology'] \n",
    "modified_df = df[~df['medical_specialty'].isin(excluded_specialities)]\n",
    "\n",
    "modified_df['medical_specialty'] = modified_df['medical_specialty'].apply(\n",
    "    lambda x: 'Neurology / Neurosurgery' if x in ['Neurology', 'Neurosurgery'] else x\n",
    ")\n",
    "\n",
    "modified_df['medical_specialty'] = modified_df['medical_specialty'].apply(\n",
    "    lambda x: 'General Medicine / SOAP / Chart / Progress Notes' if x in ['General Medicine', 'SOAP / Chart / Progress Notes'] else x\n",
    ")\n",
    "\n",
    "speciality_count = utils.class_distribution(modified_df.medical_specialty, verbose=False)\n",
    "modified_df = modified_df[modified_df.medical_specialty.isin(speciality_count[speciality_count >= MIN_SPECIALITY_THRESHOLD].index)]\n",
    "_ = utils.class_distribution(modified_df.medical_specialty, 'Medical Specialty', show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(df):\n",
    "    df['label'], uniques = pd.factorize(df['medical_specialty'])\n",
    "    print(\"Unique medical specialties:\")\n",
    "    for i, label in enumerate(uniques):\n",
    "        print(f\"{i}: {label}\")\n",
    "    return df, uniques\n",
    "\n",
    "modified_df, uniques = encode_label(modified_df)\n",
    "modified_df.sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_data(df):\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    df_resampled, y_resampled = ros.fit_resample(\n",
    "        df[['text']],\n",
    "        df['label']\n",
    "    )\n",
    "\n",
    "    df_resampled['label'] = y_resampled\n",
    "    print(f\"Resampled Shape: {df_resampled.shape}\")\n",
    "    return df_resampled\n",
    "\n",
    "df_resampled = resample_data(modified_df)\n",
    "\n",
    "train_df, test_df = train_test_split(df_resampled, test_size=DS_SPLIT, stratify=df_resampled['label'], random_state=42)\n",
    "print(f\"Train Shape: {train_df.shape}, Test Shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(tokenizer, train_df, test_df):\n",
    "    def tokenize(examples):\n",
    "        return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=MAX_SEQ_LEN)\n",
    "\n",
    "    train_ds = Dataset.from_pandas(train_df)\n",
    "    test_ds = Dataset.from_pandas(test_df)\n",
    "\n",
    "    train_ds = train_ds.map(tokenize, batched=True)\n",
    "    test_ds = test_ds.map(tokenize, batched=True)\n",
    "\n",
    "    train_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "    test_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "    return train_ds, test_ds\n",
    "\n",
    "distilbiobert_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "train_ds, test_ds = tokenize_data(distilbiobert_tokenizer, train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Fitting and Validation\n",
    "\n",
    "1. model 1 \n",
    "    - decription \n",
    "2. model 2\n",
    "    - decription "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {label: idx for idx, label in enumerate(uniques)}\n",
    "id2label = {idx: label for idx, label in enumerate(uniques)}\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=distilbiobert_tokenizer)\n",
    "distilbiobert_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(uniques),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1_weighted\": f1_score(labels, preds, average=\"weighted\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",         \n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_weighted\",\n",
    "    greater_is_better=True,\n",
    "    learning_rate=2e-5,             \n",
    "    per_device_train_batch_size=BATCH_SIZE, \n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=10,             \n",
    "    weight_decay=0.01,\n",
    "    report_to=\"none\",\n",
    "    logging_dir=None,           \n",
    "    logging_steps=-1\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=distilbiobert_model,       \n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation \n",
    "\n",
    "* Examine your models (coefficients, parameters, errors, etc...)\n",
    "\n",
    "* Compute and interpret your results in terms of accuracy, precision, recall, ROC etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results:\")\n",
    "for key, value in eval_results.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(test_ds)\n",
    "y_true = predictions.label_ids\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "classes = list(id2label.values())\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "utils.plot_confusion_matrix(cm, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(tokenizer, model, test_df):\n",
    "    def classify(text):\n",
    "        tokens = tokenizer.encode(text, return_tensors='pt', truncation=True, padding=True, max_length=MAX_SEQ_LEN)\n",
    "        tokens = tokens.to(model.device)\n",
    "        result = model(tokens)\n",
    "        return int(torch.argmax(result.logits))\n",
    "    \n",
    "    samples = pd.DataFrame()\n",
    "    for i in range(len(uniques)):\n",
    "        sample = test_df[test_df.label == i].sample(1, random_state=21)\n",
    "        samples = pd.concat([samples, sample])\n",
    "\n",
    "    samples = samples.reset_index(drop=True)\n",
    "    samples = samples.rename(columns={'label': 'true_label'})\n",
    "    samples['predicted_label'] = samples['text'].apply(classify)\n",
    "    return samples\n",
    "\n",
    "make_predictions(distilbiobert_tokenizer, distilbiobert_model, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: DistilBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing\n",
    "\n",
    "* Enumerate and present the main steps you preformed in the data preprocessing\n",
    "* Add your code and interpret the outcome of main steps/functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'distilbert-base-uncased'\n",
    "speciality_count = utils.class_distribution(df.medical_specialty, verbose=False)\n",
    "df = df[df.medical_specialty.isin(speciality_count[speciality_count >= MIN_SPECIALITY_THRESHOLD].index)]\n",
    "_ = utils.class_distribution(df.medical_specialty, 'Medical Specialty', show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, uniques = encode_label(df)\n",
    "df.sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled = resample_data(df)\n",
    "\n",
    "train_df, test_df = train_test_split(df_resampled, test_size=DS_SPLIT, stratify=df_resampled['label'], random_state=42)\n",
    "print(f\"Train Shape: {train_df.shape}, Test Shape: {test_df.shape}\")\n",
    "\n",
    "distilbert_tokenizer = DistilBertTokenizer.from_pretrained(MODEL_NAME)\n",
    "train_ds, test_ds = tokenize_data(distilbert_tokenizer, train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Fitting and Validation\n",
    "\n",
    "1. model 1 \n",
    "    - decription \n",
    "2. model 2\n",
    "    - decription "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {label: idx for idx, label in enumerate(uniques)}\n",
    "id2label = {idx: label for idx, label in enumerate(uniques)}\n",
    "\n",
    "distilbert_model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(uniques),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=distilbert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",         \n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_weighted\",\n",
    "    greater_is_better=True,\n",
    "    learning_rate=2e-5,             \n",
    "    per_device_train_batch_size=BATCH_SIZE, \n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=10,             \n",
    "    weight_decay=0.01,\n",
    "    report_to=\"none\",\n",
    "    logging_dir=None,           \n",
    "    logging_steps=-1\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=distilbert_model,       \n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation \n",
    "\n",
    "* Examine your models (coefficients, parameters, errors, etc...)\n",
    "\n",
    "* Compute and interpret your results in terms of accuracy, precision, recall, ROC etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results:\")\n",
    "for key, value in eval_results.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(test_ds)\n",
    "y_true = predictions.label_ids\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "classes = list(id2label.values())\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "utils.plot_confusion_matrix(cm, classes)\n",
    "\n",
    "make_predictions(distilbert_tokenizer, distilbert_model, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: RoBERTa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing\n",
    "\n",
    "* Enumerate and present the main steps you preformed in the data preprocessing\n",
    "* Add your code and interpret the outcome of main steps/functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATASET_PATH, usecols=['keywords', 'transcription', 'medical_specialty'])    \n",
    "\n",
    "utils = DataUtils()\n",
    "df = utils.handle_nulls(df)\n",
    "df = utils.handle_duplicates(df)\n",
    "\n",
    "df['medical_specialty'] = df['medical_specialty'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speciality_count = utils.class_distribution(df.medical_specialty, verbose=False)\n",
    "df['medical_specialty'] = df['medical_specialty'].apply(\n",
    "    lambda x: x if speciality_count[x] >= MIN_SPECIALITY_THRESHOLD else 'other')\n",
    "_ = utils.class_distribution(df.medical_specialty, 'Medical Specialty', show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, uniques = encode_label(df)\n",
    "df.sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame({\n",
    "    'text' : df['keywords']+df['transcription'],\n",
    "    'label' : df['label']\n",
    "})\n",
    "\n",
    "train_df, test_df = train_test_split(dataset, test_size=DS_SPLIT, stratify=dataset['label'], random_state=42)\n",
    "print(f\"Train Shape: {train_df.shape}, Test Shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Fitting and Validation\n",
    "\n",
    "1. model 1 \n",
    "    - decription \n",
    "2. model 2\n",
    "    - decription "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = 'roberta'\n",
    "MODEL_NAME = 'roberta-base'\n",
    "\n",
    "def compute_metrics(pred, actual):\n",
    "    return {\n",
    "        \"accuracy\": balanced_accuracy_score(actual, pred),\n",
    "        \"f1_weighted\": f1_score(actual, pred, average=\"weighted\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_available = torch.cuda.is_available()\n",
    "num_classes = len(uniques)\n",
    "\n",
    "model_args = ClassificationArgs(\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=1e-5,\n",
    "    reprocess_input_data=True,\n",
    "    save_model_every_epoch=False,\n",
    "    overwrite_output_dir= True,\n",
    "    use_early_stopping=True,\n",
    "    early_stopping_patience=2,\n",
    "    early_stopping_metric=\"mcc\",\n",
    "    early_stopping_delta=0.005\n",
    ")\n",
    "\n",
    "roberta_model = ClassificationModel(\n",
    "    MODEL_TYPE,\n",
    "    MODEL_NAME,\n",
    "    num_labels=num_classes,\n",
    "    weight=[1]*num_classes,\n",
    "    use_cuda=cuda_available,\n",
    "    args=model_args\n",
    ")\n",
    "\n",
    "roberta_model.train_model(train_df, eval_df=test_df, custom_eval_function=compute_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation \n",
    "\n",
    "* Examine your models (coefficients, parameters, errors, etc...)\n",
    "\n",
    "* Compute and interpret your results in terms of accuracy, precision, recall, ROC etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result, _, _ = roberta_model.eval_model(test_df)\n",
    "y_pred, _ = roberta_model.predict(test_df['text'].values.tolist())\n",
    "pred_result = compute_metrics(y_pred, test_df['label'])\n",
    "\n",
    "print(f\"MCC: {eval_result['mcc']}, Eval_Loss: {eval_result['eval_loss']}\")\n",
    "print(f\"Accuracy: {pred_result['accuracy']}, F1 Score: {pred_result['f1_weighted']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [uniques[i] for i in range(len(uniques))]\n",
    "cm = confusion_matrix(test_df['label'], y_pred)\n",
    "utils.plot_confusion_matrix(cm, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.DataFrame()\n",
    "for i in range(len(uniques)):\n",
    "    sample = test_df[test_df.label == i].sample(1, random_state=21)\n",
    "    samples = pd.concat([samples, sample])\n",
    "\n",
    "samples = samples.reset_index(drop=True)\n",
    "samples = samples.rename(columns={'label': 'true_label'})\n",
    "samples['predicted_label'], _ = roberta_model.predict(samples['text'].tolist())\n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues / Improvements\n",
    "1. Dataset is very small\n",
    "2. Use regularization / initialization\n",
    "3. Use cross-validaiton\n",
    "4. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  References\n",
    "   * Rajapakse, T. C., Yates, A., & de Rijke, M. (2024). Simple Transformers: Open-source for all. In *Proceedings of the 2024 Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region* (SIGIR-AP 2024, pp. 209â€“215). Association for Computing Machinery. [https://doi.org/10.1145/3673791.3698412](https://doi.org/10.1145/3673791.3698412)\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credits\n",
    "\n",
    "- If you use and/or adapt your code from existing projects, you must provide links and acknowldge the authors. Keep in mind that all documents in your projects and code will be check against the official plagiarism detection tool used by Penn State ([Turnitin](https://turnitin.psu.edu))\n",
    "\n",
    "> *This code is based on .... (if any)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of Project"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
