{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38a15fba-08c8-4590-a170-f66d1e7ffa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0562d4-8463-40c1-bd77-5d30f67a4a14",
   "metadata": {},
   "source": [
    "# Load the metrics for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5baae87-1aa2-4699-8929-16d666c22337",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/mtsamples_with_biobart_model_scores.csv')\n",
    "df = pd.concat([df, pd.read_csv('./data/mtsamples_with_gemma_model_scores.csv')], ignore_index = True)\n",
    "df = pd.concat([df, pd.read_csv('./data/mtsamples_with_llama_model_scores.csv')], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc27bca-1278-489f-a710-17cc70525716",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aefe17-c6b2-4ce2-bcae-443312b7709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1381d54-9987-4028-b3e1-dfc96c9fe425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model-name\n",
       "biobart      4999\n",
       "med-gemma    4999\n",
       "med-llama    4999\n",
       "Name: Unnamed: 0, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('model-name').count().iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46b3448-1900-41f7-a24c-7129421322f7",
   "metadata": {},
   "source": [
    "# Metrics for the human-entered summaries\n",
    "\n",
    "the source values are the same for all models, so just pick one and get the averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c34a0c78-ace6-4419-8d57-362c579c81a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rougeL_f1_source          0.088913\n",
       "bertscore_f1_source       0.485023\n",
       "bleurt_source            -0.523850\n",
       "coherence-score_source    0.574467\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics_human =  df[df['model-name'] == 'biobart'][['rougeL_f1_source', 'bertscore_f1_source', 'bleurt_source', 'coherence-score_source']].mean()\n",
    "df_metrics_human"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004450ec-96da-40d0-97d6-22d98ea52f26",
   "metadata": {},
   "source": [
    "# Metrics for the machine-generated summaries for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6c9c36b-bc64-481e-9efe-80abc4dd0921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rougeL_f1_dest</th>\n",
       "      <th>bertscore_f1_dest</th>\n",
       "      <th>bleurt_dest</th>\n",
       "      <th>hallucination-score</th>\n",
       "      <th>coherence-score_dest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model-name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>biobart</th>\n",
       "      <td>0.070512</td>\n",
       "      <td>0.463525</td>\n",
       "      <td>-0.585942</td>\n",
       "      <td>0.438506</td>\n",
       "      <td>0.417923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med-gemma</th>\n",
       "      <td>0.255740</td>\n",
       "      <td>0.580975</td>\n",
       "      <td>-0.437296</td>\n",
       "      <td>0.363880</td>\n",
       "      <td>0.738622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med-llama</th>\n",
       "      <td>0.097775</td>\n",
       "      <td>0.504987</td>\n",
       "      <td>-0.571876</td>\n",
       "      <td>0.317492</td>\n",
       "      <td>0.781731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rougeL_f1_dest  bertscore_f1_dest  bleurt_dest  \\\n",
       "model-name                                                   \n",
       "biobart           0.070512           0.463525    -0.585942   \n",
       "med-gemma         0.255740           0.580975    -0.437296   \n",
       "med-llama         0.097775           0.504987    -0.571876   \n",
       "\n",
       "            hallucination-score  coherence-score_dest  \n",
       "model-name                                             \n",
       "biobart                0.438506              0.417923  \n",
       "med-gemma              0.363880              0.738622  \n",
       "med-llama              0.317492              0.781731  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics_models = df.groupby('model-name')[['rougeL_f1_dest', 'bertscore_f1_dest', 'bleurt_dest', 'hallucination-score', 'coherence-score_dest']].mean()\n",
    "df_metrics_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "407e949a-9223-4b1c-a7ff-76d9dc1843d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rougeL_f1_diff</th>\n",
       "      <th>bertscore_f1_diff</th>\n",
       "      <th>bleurt_diff</th>\n",
       "      <th>coherence-score_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model-name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>biobart</th>\n",
       "      <td>-0.018400</td>\n",
       "      <td>-0.021498</td>\n",
       "      <td>-0.062092</td>\n",
       "      <td>-0.156544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med-gemma</th>\n",
       "      <td>0.166827</td>\n",
       "      <td>0.095952</td>\n",
       "      <td>0.086554</td>\n",
       "      <td>0.164155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med-llama</th>\n",
       "      <td>0.008862</td>\n",
       "      <td>0.019964</td>\n",
       "      <td>-0.048026</td>\n",
       "      <td>0.207264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rougeL_f1_diff  bertscore_f1_diff  bleurt_diff  \\\n",
       "model-name                                                   \n",
       "biobart          -0.018400          -0.021498    -0.062092   \n",
       "med-gemma         0.166827           0.095952     0.086554   \n",
       "med-llama         0.008862           0.019964    -0.048026   \n",
       "\n",
       "            coherence-score_diff  \n",
       "model-name                        \n",
       "biobart                -0.156544  \n",
       "med-gemma               0.164155  \n",
       "med-llama               0.207264  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([\n",
    "        df_metrics_models.rougeL_f1_dest - df_metrics_human.rougeL_f1_source, \n",
    "        df_metrics_models.bertscore_f1_dest - df_metrics_human.bertscore_f1_source,\n",
    "        df_metrics_models.bleurt_dest - df_metrics_human.bleurt_source,\n",
    "        df_metrics_models['coherence-score_dest'] - df_metrics_human['coherence-score_source'],\n",
    "    \n",
    "    ], axis = 1).rename(columns = {'rougeL_f1_dest': 'rougeL_f1_diff', \n",
    "                                   'bertscore_f1_dest': 'bertscore_f1_diff', \n",
    "                                   'bleurt_dest': 'bleurt_diff', \n",
    "                                   'coherence-score_dest': 'coherence-score_diff'})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f84e3b-d191-4481-b14f-9ad9e9c37790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
