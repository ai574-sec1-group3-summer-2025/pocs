{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "709fc424-02af-466b-a728-0dd4067dfbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-09 15:51:01.136126: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-09 15:51:01.166651: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-09 15:51:01.166675: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-09 15:51:01.167492: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-09 15:51:01.172802: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-09 15:51:01.733579: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/kilnaar/anaconda3/envs/ai574-pocs/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from rouge_score import rouge_scorer\n",
    "import evaluate\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f317d146-d2d6-4ecd-a3ca-66448ca2609a",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b23adc",
   "metadata": {},
   "source": [
    "## ROUGE F1 Scores\n",
    "\n",
    "An older-fashioned statistical set of metrics for similarity, typically used for summarizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81f840d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_calcer = rouge_scorer.RougeScorer([\n",
    "    'rougeL'\n",
    "], use_stemmer = True)\n",
    "\n",
    "def calc_rouge(short_text, full_text):\n",
    "    try:\n",
    "        rouges = rouge_calcer.score(short_text, full_text)\n",
    "        return rouges['rougeL'][2]\n",
    "    except Exception as e:\n",
    "        return 0.0\n",
    "\n",
    "def calc_rouge_pair(row):\n",
    "    return calc_rouge(row['description'], row['transcription']), calc_rouge(row[f'model-summary'], row['transcription'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f1139a",
   "metadata": {},
   "source": [
    "## BERTScore\n",
    "\n",
    "Uses embeddings from the BERT transformer model to judge similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6182766",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "def calc_bertscore(short_text, full_text):\n",
    "    try:\n",
    "        result = bertscore.compute(\n",
    "                predictions = [short_text],\n",
    "                references = [full_text],\n",
    "                model_type = \"microsoft/deberta-large-mnli\",\n",
    "                lang = \"en\",\n",
    "                device = \"cuda:0\"\n",
    "        )\n",
    "\n",
    "        return result[\"f1\"][0]\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def calc_bertscore_pair(row):\n",
    "    return pd.Series([calc_bertscore(row['description'], row['transcription']), calc_bertscore(row[f'model-summary'], row['transcription'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8b2599",
   "metadata": {},
   "source": [
    "## BLEURT\n",
    "\n",
    "A regression model based on BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a72664ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint /mnt/data/hf/metrics/bleurt/bleurt-tiny-128/downloads/extracted/599cd3ff6a3bbad54e145d867ccea405bb98c2b832fb29b50fb02089a1026530/bleurt-tiny-128.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint /mnt/data/hf/metrics/bleurt/bleurt-tiny-128/downloads/extracted/599cd3ff6a3bbad54e145d867ccea405bb98c2b832fb29b50fb02089a1026530/bleurt-tiny-128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Config file found, reading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Config file found, reading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Will load checkpoint bert_custom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Will load checkpoint bert_custom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loads full paths and checks that files exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loads full paths and checks that files exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... name:bert_custom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... name:bert_custom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... vocab_file:vocab.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... vocab_file:vocab.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... bert_config_file:bert_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... bert_config_file:bert_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... do_lower_case:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... do_lower_case:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... max_seq_length:128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... max_seq_length:128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating BLEURT scorer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating BLEURT scorer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating WordPiece tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating WordPiece tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating Eager Mode predictor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating Eager Mode predictor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model.\n",
      "2025-08-09 15:51:06.563567: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-09 15:51:06.564449: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    }
   ],
   "source": [
    "bleurt = evaluate.load(\"bleurt\", config_name = \"bleurt-tiny-128\")\n",
    "\n",
    "def calc_bleu(short_text, full_text):\n",
    "    # this was slower on GPU, I think it doesn't paralleize well because of how small the model is\n",
    "    with tf.device(\"/CPU:0\"):\n",
    "        try:\n",
    "            result = bleurt.compute(\n",
    "                    predictions = [short_text],\n",
    "                    references = [full_text],\n",
    "                    )\n",
    "            return result[\"scores\"][0]\n",
    "        except:\n",
    "            return 0.0\n",
    "\n",
    "def calc_bleu_pair(row):\n",
    "    return pd.Series([calc_bleu(row['description'], row['transcription']), calc_bleu(row[f'model-summary'], row['transcription'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc12339-0ead-4d4d-b529-bf074b6ca203",
   "metadata": {},
   "source": [
    "## HHEM 2.1 model from Vectara (WIP)\n",
    "\n",
    "Languaged-model-based system for detecting hallucinations in other LM operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d6eb47e-1abb-406c-92b6-35c6d62bbbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact hallucination_hhem_scorer:v0, 421.31MB. 8 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   8 of 8 files downloaded.  \n",
      "Done. 0:0:1.0 (411.0MB/s)\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"WANDB_BASE_URL\"] = \"https://api.wandb.ai\"\n",
    "from weave.scorers import WeaveHallucinationScorerV1\n",
    "\n",
    "hallucination_scorer = WeaveHallucinationScorerV1(device = 'cuda:0')\n",
    "\n",
    "def hallucination_score(query, context, output):\n",
    "    try:\n",
    "        result = hallucination_scorer.score(\n",
    "            query = query,\n",
    "            context = context,\n",
    "            output = output,            \n",
    "        )\n",
    "    \n",
    "        return result.metadata['score']\n",
    "    except:\n",
    "        return 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7713af02-7125-4ccc-b7a4-9870074add55",
   "metadata": {},
   "source": [
    "## Coherence\n",
    "\n",
    "A fine-tuned deberta-small-long-nli Small Language Model that ensures the writing doesn't contradict itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f6864fe-f1d0-4d09-9ea4-46518aa94a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact coherence_scorer:v0, 549.59MB. 21 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   21 of 21 files downloaded.  \n",
      "Done. 0:0:1.1 (489.8MB/s)\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "os.environ[\"USE_TF\"] = \"0\"\n",
    "os.environ[\"WANDB_BASE_URL\"] = \"https://api.wandb.ai\"\n",
    "from weave.scorers import WeaveCoherenceScorerV1\n",
    "\n",
    "coherence_scorer = WeaveCoherenceScorerV1(device = 'cuda:0')\n",
    "\n",
    "def coherence_score(query, output):\n",
    "    try:\n",
    "        result = coherence_scorer.score(\n",
    "            query = query,\n",
    "            output = output\n",
    "        )\n",
    "    \n",
    "        return result.metadata['score']\n",
    "    except:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8978f851-4df4-4b48-8d0f-bf44117ad662",
   "metadata": {},
   "source": [
    "## Calculate and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2ed0a42-0b09-41f2-914d-67d672689bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "WARNING:weave.trace.op:Warning: Traces will not be logged. Call weave.init to log your traces to a project.\n",
      " (subsequent messages of this type will be suppressed)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (711 > 512). Running this sequence through the model will result in indexing errors\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "model_names = [\n",
    "    'biobart',\n",
    "    'gemma',\n",
    "    'llama',    \n",
    "]\n",
    "\n",
    "for test_model_name in model_names:\n",
    "    df = pd.read_csv(f'./data/mtsamples_with_{test_model_name}.csv')\n",
    "    df['transcription'] = df.transcription.astype(str)\n",
    "\n",
    "    df[['rougeL_f1_source', 'rougeL_f1_dest']] = df.apply(calc_rouge_pair, axis = 1, result_type = 'expand')\n",
    "    df[['bertscore_f1_source', 'bertscore_f1_dest']] = df.apply(calc_bertscore_pair, axis = 1)\n",
    "    df[['bleurt_source', 'bleurt_dest']] = df.apply(calc_bleu_pair, axis = 1)\n",
    "    df['hallucination-score'] = df.apply(lambda x: hallucination_score(x.transcription, x.description, x['model-summary']), axis = 1)\n",
    "    df['coherence-score_source'] = df.apply(lambda x: coherence_score(x.transcription, x['description']), axis = 1)\n",
    "    df['coherence-score_dest'] = df.apply(lambda x: coherence_score(x.transcription, x['model-summary']), axis = 1)\n",
    "\n",
    "    # Save this model's stats to disk\n",
    "    df.to_csv(f'./data/mtsamples_with_{test_model_name}_model_scores.csv', index = False, quoting = csv.QUOTE_NONNUMERIC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e36d60-bd08-4ad0-80f3-6798e2cec5b9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Aggregate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98794ac-0c2f-49ab-8963-6e66c11dc098",
   "metadata": {},
   "source": [
    "## Load the metrics for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85af01cd-0902-412f-8a45-512c34d63a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/mtsamples_with_biobart_model_scores.csv')\n",
    "df = pd.concat([df, pd.read_csv('./data/mtsamples_with_gemma_model_scores.csv')], ignore_index = True)\n",
    "df = pd.concat([df, pd.read_csv('./data/mtsamples_with_llama_model_scores.csv')], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d6be2d-2a91-47e0-a22a-21d074a0ecb5",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfe21d66-f1f3-4263-959e-ed8ef180cbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>transcription</th>\n",
       "      <th>keywords</th>\n",
       "      <th>model-summary</th>\n",
       "      <th>model-name</th>\n",
       "      <th>rougeL_f1_source</th>\n",
       "      <th>rougeL_f1_dest</th>\n",
       "      <th>bertscore_f1_source</th>\n",
       "      <th>bertscore_f1_dest</th>\n",
       "      <th>bleurt_source</th>\n",
       "      <th>bleurt_dest</th>\n",
       "      <th>hallucination-score</th>\n",
       "      <th>coherence-score_source</th>\n",
       "      <th>coherence-score_dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A 23-year-old white female presents with comp...</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "      <td>Allergic Rhinitis</td>\n",
       "      <td>SUBJECTIVE:,  This 23-year-old white female pr...</td>\n",
       "      <td>allergy / immunology, allergic rhinitis, aller...</td>\n",
       "      <td>SUBJECTIVITY:  This 25 year old white female....</td>\n",
       "      <td>biobart</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.460195</td>\n",
       "      <td>0.501567</td>\n",
       "      <td>-0.578639</td>\n",
       "      <td>-0.751127</td>\n",
       "      <td>0.837365</td>\n",
       "      <td>0.868146</td>\n",
       "      <td>0.681641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Consult for laparoscopic gastric bypass.</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Laparoscopic Gastric Bypass Consult - 2</td>\n",
       "      <td>PAST MEDICAL HISTORY:, He has difficulty climb...</td>\n",
       "      <td>bariatrics, laparoscopic gastric bypass, weigh...</td>\n",
       "      <td>PASTMEDICAL HOSPITAL: He is a retired male. he...</td>\n",
       "      <td>biobart</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.390673</td>\n",
       "      <td>0.470543</td>\n",
       "      <td>-0.645709</td>\n",
       "      <td>-0.409956</td>\n",
       "      <td>0.913990</td>\n",
       "      <td>0.325240</td>\n",
       "      <td>0.438955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Consult for laparoscopic gastric bypass.</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Laparoscopic Gastric Bypass Consult - 1</td>\n",
       "      <td>HISTORY OF PRESENT ILLNESS: , I have seen ABC ...</td>\n",
       "      <td>bariatrics, laparoscopic gastric bypass, heart...</td>\n",
       "      <td>HISTORY of PRESENTILLNESS, among other bilater...</td>\n",
       "      <td>biobart</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.026525</td>\n",
       "      <td>0.408516</td>\n",
       "      <td>0.419701</td>\n",
       "      <td>-0.911012</td>\n",
       "      <td>-0.542565</td>\n",
       "      <td>0.319041</td>\n",
       "      <td>0.836381</td>\n",
       "      <td>0.324871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2-D M-Mode. Doppler.</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 1</td>\n",
       "      <td>2-D M-MODE: , ,1.  Left atrial enlargement wit...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d m-mode, dopple...</td>\n",
       "      <td>2-D R-MODE and M-Mode: , .1. :  Left ventricu...</td>\n",
       "      <td>biobart</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.449169</td>\n",
       "      <td>0.599963</td>\n",
       "      <td>-0.929891</td>\n",
       "      <td>-0.289554</td>\n",
       "      <td>0.707408</td>\n",
       "      <td>0.768800</td>\n",
       "      <td>0.369644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2-D Echocardiogram</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 2</td>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d, doppler, echo...</td>\n",
       "      <td>1. .  There appears  the left ventricular cham...</td>\n",
       "      <td>biobart</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.119850</td>\n",
       "      <td>0.390977</td>\n",
       "      <td>0.553946</td>\n",
       "      <td>-0.719434</td>\n",
       "      <td>-0.249013</td>\n",
       "      <td>0.709367</td>\n",
       "      <td>0.263281</td>\n",
       "      <td>0.431459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0   A 23-year-old white female presents with comp...   \n",
       "1           1           Consult for laparoscopic gastric bypass.   \n",
       "2           2           Consult for laparoscopic gastric bypass.   \n",
       "3           3                             2-D M-Mode. Doppler.     \n",
       "4           4                                 2-D Echocardiogram   \n",
       "\n",
       "             medical_specialty                                sample_name  \\\n",
       "0         Allergy / Immunology                         Allergic Rhinitis    \n",
       "1                   Bariatrics   Laparoscopic Gastric Bypass Consult - 2    \n",
       "2                   Bariatrics   Laparoscopic Gastric Bypass Consult - 1    \n",
       "3   Cardiovascular / Pulmonary                    2-D Echocardiogram - 1    \n",
       "4   Cardiovascular / Pulmonary                    2-D Echocardiogram - 2    \n",
       "\n",
       "                                       transcription  \\\n",
       "0  SUBJECTIVE:,  This 23-year-old white female pr...   \n",
       "1  PAST MEDICAL HISTORY:, He has difficulty climb...   \n",
       "2  HISTORY OF PRESENT ILLNESS: , I have seen ABC ...   \n",
       "3  2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
       "4  1.  The left ventricular cavity size and wall ...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  allergy / immunology, allergic rhinitis, aller...   \n",
       "1  bariatrics, laparoscopic gastric bypass, weigh...   \n",
       "2  bariatrics, laparoscopic gastric bypass, heart...   \n",
       "3  cardiovascular / pulmonary, 2-d m-mode, dopple...   \n",
       "4  cardiovascular / pulmonary, 2-d, doppler, echo...   \n",
       "\n",
       "                                       model-summary model-name  \\\n",
       "0   SUBJECTIVITY:  This 25 year old white female....    biobart   \n",
       "1  PASTMEDICAL HOSPITAL: He is a retired male. he...    biobart   \n",
       "2  HISTORY of PRESENTILLNESS, among other bilater...    biobart   \n",
       "3   2-D R-MODE and M-Mode: , .1. :  Left ventricu...    biobart   \n",
       "4  1. .  There appears  the left ventricular cham...    biobart   \n",
       "\n",
       "   rougeL_f1_source  rougeL_f1_dest  bertscore_f1_source  bertscore_f1_dest  \\\n",
       "0          0.086957        0.100000             0.460195           0.501567   \n",
       "1          0.005495        0.046875             0.390673           0.470543   \n",
       "2          0.010870        0.026525             0.408516           0.419701   \n",
       "3          0.121951        0.280000             0.449169           0.599963   \n",
       "4          0.008197        0.119850             0.390977           0.553946   \n",
       "\n",
       "   bleurt_source  bleurt_dest  hallucination-score  coherence-score_source  \\\n",
       "0      -0.578639    -0.751127             0.837365                0.868146   \n",
       "1      -0.645709    -0.409956             0.913990                0.325240   \n",
       "2      -0.911012    -0.542565             0.319041                0.836381   \n",
       "3      -0.929891    -0.289554             0.707408                0.768800   \n",
       "4      -0.719434    -0.249013             0.709367                0.263281   \n",
       "\n",
       "   coherence-score_dest  \n",
       "0              0.681641  \n",
       "1              0.438955  \n",
       "2              0.324871  \n",
       "3              0.369644  \n",
       "4              0.431459  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13368d31-5129-4ecf-abc4-55b3e763578e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model-name\n",
       "biobart      4999\n",
       "med-gemma    4999\n",
       "med-llama    4999\n",
       "Name: Unnamed: 0, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('model-name').count().iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7ad687-d906-4149-9668-7b9603f06d26",
   "metadata": {},
   "source": [
    "# Metrics for the human-entered summaries\n",
    "\n",
    "the source values are the same for all models, so just pick one and get the averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b4741bd-67c1-4901-9b46-8d127f4de25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rougeL_f1_source          0.088913\n",
       "bertscore_f1_source       0.485023\n",
       "bleurt_source            -0.523850\n",
       "coherence-score_source    0.574467\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics_human =  df[df['model-name'] == 'biobart'][['rougeL_f1_source', 'bertscore_f1_source', 'bleurt_source', 'coherence-score_source']].mean()\n",
    "df_metrics_human"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8cc03f-2177-4397-bf44-41eb703abbc4",
   "metadata": {},
   "source": [
    "# Metrics for the machine-generated summaries for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee70ec17-8b48-452b-877d-17ab55fe868c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rougeL_f1_dest</th>\n",
       "      <th>bertscore_f1_dest</th>\n",
       "      <th>bleurt_dest</th>\n",
       "      <th>hallucination-score</th>\n",
       "      <th>coherence-score_dest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model-name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>biobart</th>\n",
       "      <td>0.070512</td>\n",
       "      <td>0.463525</td>\n",
       "      <td>-0.585942</td>\n",
       "      <td>0.438506</td>\n",
       "      <td>0.417923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med-gemma</th>\n",
       "      <td>0.255567</td>\n",
       "      <td>0.580905</td>\n",
       "      <td>-0.437547</td>\n",
       "      <td>0.365952</td>\n",
       "      <td>0.738806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med-llama</th>\n",
       "      <td>0.097805</td>\n",
       "      <td>0.505136</td>\n",
       "      <td>-0.572614</td>\n",
       "      <td>0.321530</td>\n",
       "      <td>0.781948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rougeL_f1_dest  bertscore_f1_dest  bleurt_dest  \\\n",
       "model-name                                                   \n",
       "biobart           0.070512           0.463525    -0.585942   \n",
       "med-gemma         0.255567           0.580905    -0.437547   \n",
       "med-llama         0.097805           0.505136    -0.572614   \n",
       "\n",
       "            hallucination-score  coherence-score_dest  \n",
       "model-name                                             \n",
       "biobart                0.438506              0.417923  \n",
       "med-gemma              0.365952              0.738806  \n",
       "med-llama              0.321530              0.781948  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics_models = df.groupby('model-name')[['rougeL_f1_dest', 'bertscore_f1_dest', 'bleurt_dest', 'hallucination-score', 'coherence-score_dest']].mean()\n",
    "df_metrics_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cd3501-f672-4499-a4da-fc99912ace17",
   "metadata": {},
   "source": [
    "# Comparison of machine-generated and human-generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe434c38-0d6b-4957-8a99-22923b479bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rougeL_f1_diff</th>\n",
       "      <th>bertscore_f1_diff</th>\n",
       "      <th>bleurt_diff</th>\n",
       "      <th>coherence-score_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model-name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>biobart</th>\n",
       "      <td>-0.018400</td>\n",
       "      <td>-0.021498</td>\n",
       "      <td>-0.062092</td>\n",
       "      <td>-0.156544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med-gemma</th>\n",
       "      <td>0.166655</td>\n",
       "      <td>0.095883</td>\n",
       "      <td>0.086304</td>\n",
       "      <td>0.164339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med-llama</th>\n",
       "      <td>0.008892</td>\n",
       "      <td>0.020113</td>\n",
       "      <td>-0.048764</td>\n",
       "      <td>0.207481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rougeL_f1_diff  bertscore_f1_diff  bleurt_diff  \\\n",
       "model-name                                                   \n",
       "biobart          -0.018400          -0.021498    -0.062092   \n",
       "med-gemma         0.166655           0.095883     0.086304   \n",
       "med-llama         0.008892           0.020113    -0.048764   \n",
       "\n",
       "            coherence-score_diff  \n",
       "model-name                        \n",
       "biobart                -0.156544  \n",
       "med-gemma               0.164339  \n",
       "med-llama               0.207481  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([\n",
    "        df_metrics_models.rougeL_f1_dest - df_metrics_human.rougeL_f1_source, \n",
    "        df_metrics_models.bertscore_f1_dest - df_metrics_human.bertscore_f1_source,\n",
    "        df_metrics_models.bleurt_dest - df_metrics_human.bleurt_source,\n",
    "        df_metrics_models['coherence-score_dest'] - df_metrics_human['coherence-score_source'],\n",
    "    \n",
    "    ], axis = 1).rename(columns = {'rougeL_f1_dest': 'rougeL_f1_diff', \n",
    "                                   'bertscore_f1_dest': 'bertscore_f1_diff', \n",
    "                                   'bleurt_dest': 'bleurt_diff', \n",
    "                                   'coherence-score_dest': 'coherence-score_diff'})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c064ca7b-3d39-4c01-bc83-fa52e5df0fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e268fea-4855-4a94-97c2-6b84755b977f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
