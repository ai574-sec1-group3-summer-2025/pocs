{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63812aa9-b420-47ff-9eb1-1ad6d6a46353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6031840c-79c4-4ce4-9fbc-d2b2cf11c1ed",
   "metadata": {},
   "source": [
    "# Load model\n",
    "https://huggingface.co/luqh/ClinicalT5-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a649315d-4259-4080-b6d6-b2ec974f9122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "All Flax model weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "Some weights of T5ForConditionalGeneration were not initialized from the Flax model and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"luqh/ClinicalT5-large\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name, model_max_length = 8192)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name, from_flax = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608af921-9868-49f9-a3e0-575cfafb532e",
   "metadata": {},
   "source": [
    "# Some medical text\n",
    "\n",
    "Not that this will fail if there are too many tokens. We'll have to do some chunking or RAG in order to\n",
    "deal with the small context window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3bdeb259-5f30-4dd2-8284-3a1099c00756",
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_text = \"\"\"\n",
    "DESCRIPTION OF PROCEDURE:  ,After induction of general anesthesia, the patient was placed prone on the operating room table resting on chest rolls.  Her face was resting in a pink foam headrest.  Extreme care was taken positioning her because she weighs 92 kg.  There was a lot of extra padding for her limbs and her limbs were positioned comfortably.  The arms were not hyperextended.  Great care was taken with positioning of the head and making sure there was no pressure on her eyes especially since she already has visual disturbance.  A Foley catheter was in place.  She received IV Cipro 400 mg because she is allergic to most antibiotics.,Fluoroscopy was used to locate the lower end of the fractured catheter and the skin was marked.  It was also marked where we would try to insert the new catheter at the L4 or L3 interspinous space.,The patient was then prepped and draped in a sterile manner.,A 7-cm incision was made over the L1 lamina.  The incision was carried down through the fascia all the way down to the spinous processes.  A self-retaining McCullough retractor was placed.  The laminae were quite deep.  The microscope was brought in and using the Midas Rex drill with the AM-8 bit and removing some of the spinous process of L1-L2 with double-action rongeurs, the laminotomy was then done using the drill and great care was taken and using a 2-mm rongeur, the last layer of lamina was removed exposing the epidural fat and dura.  The opening in the bone was 1.5 x 1.5 cm.,Occasionally, bipolar cautery was used for bleeding of epidural veins, but this cautery was kept to a minimum.,Under high magnification, the dura was opened with an 11 blade and microscissors.  At first, there was a linear incision vertically to the left of midline, and I then needed to make a horizontal incision more towards the right.  The upper aspect of the cauda equina was visualized and perhaps the lower end of the conus.  Microdissection under high magnification did not expose the catheter.  The fluoroscope was brought in 2 more times including getting a lateral view and the fluoroscope appeared to show that the catheter should be in this location.,I persisted with intensive microdissection and finally we could see the catheter deep to the nerves and I was able to pull it out with the microforceps.,The wound was irrigated with bacitracin irrigation.,At this point, I then attempted lumbar puncture by making a small incision with an 11 blade in the L4 interspinous space and then later in the L3 interspinous space and attempted to puncture the dural sac with the Tuohy needle.  Dr. Y also tried.  Despite using the fluoroscope and our best attempts, we were not able to convincingly puncture the lumbar subarachnoid space and so the attempted placement of the new lumbar catheter had to be abandoned.  It will be done at a later date.,I felt it was unsafe to place a new catheter at this existing laminotomy site because it was very high up near the conus.  The potential for complications involving her spinal cord was greater and we have already had a complication of the catheter now and I just did not think it was safe to put in this location.,Under high magnification, the dura was closed with #6-0 PDS interrupted sutures.,After the dura was closed, a piece of Gelfoam was placed over the dura.  The paraspinous muscles were closed with 0 Vicryl interrupted sutures.  The subcutaneous fascia was also closed with 0 Vicryl interrupted suture.  The subcutaneous layer was closed with #2-0 Vicryl interrupted suture and the skin with #4-0 Vicryl Rapide.  The 4-0 Vicryl Rapide sutures were also used at the lumbar puncture sites to close the skin.,The patient was then turned carefully on to her bed after sterile dressings were applied and then taken to the recovery room.  The patient tolerated procedure well.  No complications.  Sponge and needle counts correct.  Blood loss minimal, none replaced.  This procedure took 5 hours.  This case was also extremely difficult due to patient's size and the difficulty of locating the catheter deep to the cauda equina.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69835ce5-5ab0-45ab-9f92-2aa0e166cdef",
   "metadata": {},
   "source": [
    "# Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e925c8c0-0e7b-463e-bd1b-e416b31f40ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"summarize clinical note: \" + medical_text.strip()\n",
    "inputs = tokenizer(prompt, return_tensors = \"pt\", truncation = True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    summary_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens = 128,\n",
    "        min_length = 60,        \n",
    "        num_beams = 5,\n",
    "        length_penalty = 2.0,        # prefer longer response\n",
    "        early_stopping = False,      # let all beams finish\n",
    "        no_repeat_ngram_size = 3     # reduce verbatim copying\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2df5fcb5-43f4-4416-8743-4221034a90f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - the patient was placed on a - she was placed prone on the operating room table resting on chest rolls with her head resting in a pink foam headrest. she was positioned comfortably. she had a she is very obese. she received she received the the the lamina was opened. the skin was marked.,     and and\n"
     ]
    }
   ],
   "source": [
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens = True)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532e3322-eed5-47dd-80f6-ef5d8c6787ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
